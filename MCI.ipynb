{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "#          1. Linear Congruential Generator (LCG)\n",
    "# ------------------------------------------------------\n",
    "def lcg(seed = 123):\n",
    "    \"\"\"\n",
    "    Simple LCG using Park-Miller values.\n",
    "    Each call updates seed and returns a U(0,1) random number.\n",
    "    \"\"\"\n",
    "    a = 16807\n",
    "    m = 2**31 - 1\n",
    "    seed = (a * seed) % m\n",
    "    return seed, seed / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from basic_operations import mean, var, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializaion\n",
    "a,b = 0,np.pi # limits\n",
    "N = int(1e3) # no. of samples\n",
    "seed = 123 \n",
    "xrand = np.zeros(N) # array of samples\n",
    "\n",
    "for i in range(len(xrand)):\n",
    "    seed, xrand[i] =  lcg(seed)\n",
    "    xrand[i]  = a + (b-a) * xrand[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to integrate\n",
    "def func(x):\n",
    "    return np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integral = 0\n",
    "for i in range(N):\n",
    "    integral += func(xrand[i])\n",
    "\n",
    "answer = (b-a)/float(N) * integral\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return 4 / (1 + x**2)\n",
    "\n",
    "a,b = 0,1 # limits of integration\n",
    "integral = 0\n",
    "N = int(1e3) # no of sampled points\n",
    "\n",
    "xrand = np.zeros(N) # stores sampled points\n",
    "f_values = np.zeros(N) # stores f(x) for each point\n",
    "\n",
    "# populating xrand\n",
    "for i in range(len(xrand)):\n",
    "    seed, xrand[i] =  lcg(seed)\n",
    "    xrand[i]  = a + (b-a) * xrand[i]\n",
    "\n",
    "# populating f_values\n",
    "for i in range(N):\n",
    "    f_values[i] = func(xrand[i])\n",
    "\n",
    "\n",
    "integral = np.mean(f_values) * (b-a)\n",
    "print(\"Integral: \", integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_error = np.sqrt(np.var(f_values))/np.sqrt(N)\n",
    "confidence_interval = [integral - 2.576 * standard_error, integral + 2.576 * standard_error]\n",
    "abs_error = np.abs(integral - np.pi)\n",
    "print(\"Standard error: \", standard_error)\n",
    "print(\"confidence_interval: \", confidence_interval)\n",
    "print(\"absolute error: \", abs_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating for different values of N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 0, 1\n",
    "integral = 0\n",
    "integral_vals = []\n",
    "N_vals = [1e3, 1e4, 1e5,1e6]\n",
    "margins = []\n",
    "se_squared = []\n",
    "variances = []\n",
    "\n",
    "\n",
    "for i in N_vals:\n",
    "    N = int(i)\n",
    "\n",
    "    xrand = np.zeros(N)\n",
    "    f_values = np.zeros(N)\n",
    "\n",
    "    for i in range(len(xrand)):\n",
    "        seed, xrand[i] =  lcg(seed)\n",
    "        xrand[i]  = a + (b-a) * xrand[i]\n",
    "\n",
    "    for i in range(N):\n",
    "        f_values[i] = func(xrand[i])\n",
    "\n",
    "\n",
    "    integral = np.mean(f_values) * (b-a)\n",
    "    standard_error = np.sqrt(np.var(f_values))/np.sqrt(N) * (b-a)\n",
    "    confidence_interval = [integral - 2.576 * standard_error, integral + 2.576 * standard_error]\n",
    "    abs_error = np.abs(integral - np.pi)\n",
    "    integral_vals.append(integral)\n",
    "    margins.append(2.576 * standard_error)\n",
    "    variances.append(np.var((f_values)))\n",
    "    se_squared.append(standard_error**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error bars\n",
    "# fmt='-o' connects points with a line and uses circle markers\n",
    "# capsize=5 adds the horizontal lines at the top/bottom of the error bars\n",
    "plt.errorbar(N_vals, integral_vals, yerr=margins, fmt='-o', \n",
    "             capsize=5, label=r'$\\hat{I} \\pm 99\\% CI$')\n",
    "\n",
    "# Plot the True Pi reference line\n",
    "plt.axhline(y=np.pi, color='r', linestyle='--', label=r'True $\\pi$')\n",
    "\n",
    "# 5. Formatting to match the screenshot\n",
    "plt.xscale('log') # Logarithmic X-axis for 10^3, 10^4...\n",
    "plt.xlabel(r'Number of samples $N$')\n",
    "plt.ylabel(r'Estimate $\\hat{I}$')\n",
    "plt.title('Convergence of Monte Carlo Estimate')\n",
    "plt.grid(True, which=\"both\", linestyle=':', alpha=0.7) # Dotted grid lines\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Use loglog for both axes as shown in the screenshot\n",
    "plt.loglog(N_vals, variances, 'o-', label=r'Var($f$)')\n",
    "plt.loglog(N_vals, se_squared, 's--', label=r'SE$^2 = \\mathrm{Var}(f)/N$')\n",
    "\n",
    "# 5. Formatting\n",
    "plt.xlabel(r'Number of samples $N$')\n",
    "plt.ylabel(r'Variance / SE$^2$')\n",
    "plt.title('Scaling of Variance and Standard Error')\n",
    "plt.grid(True, which=\"both\", linestyle=':', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-d Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 1. LCG Function ---\n",
    "def lcg(seed):\n",
    "    a = 16807\n",
    "    m = 2**31 - 1\n",
    "    seed = (a * seed) % m\n",
    "    return seed, seed / m\n",
    "\n",
    "# --- 2. The 6D Function g(x) ---\n",
    "def g(x):\n",
    "    # x is an array of size 6\n",
    "    # Term 1: Sum of squares x_k^2 for k=0 to 5\n",
    "    term1 = sum(x**2)\n",
    "    \n",
    "    # Term 2: Sum of (x_k - x_{k+3})^2 for k=0 to 2\n",
    "    term2 = (x[0] - x[3])**2 + (x[1] - x[4])**2 + (x[2] - x[5])**2\n",
    "    \n",
    "    return np.exp(-term1 - 0.5 * term2)\n",
    "\n",
    "# --- 3. Setup ---\n",
    "a_lim, b_lim = -5, 5 # limits of integral\n",
    "d = 6 # dimensions\n",
    "vol = (b_lim - a_lim)**d  # Volume of the 6D hypercube (10^6)\n",
    "true_val = 10.966         # Given in problem\n",
    "seed = 123456\n",
    "\n",
    "N_vals = [1e4, 1e5, 1e6]\n",
    "\n",
    "print(f\"{'N':<9} {'Estimate':<10} {'SE':<10} {'95% CI':<20} {'Rel Error':<10} {'R (Ratio)'}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for n_val in N_vals:\n",
    "    N = int(n_val)\n",
    "    \n",
    "    # Pre-allocate\n",
    "    g_values = np.zeros(N)\n",
    "    \n",
    "    # --- Generation & Evaluation Loop ---\n",
    "    for i in range(N):\n",
    "        # Generate 6 random numbers\n",
    "        x_point = np.zeros(d)\n",
    "        for j in range(d):\n",
    "            seed, u = lcg(seed)\n",
    "            # SCALE CORRECTLY: a + (b-a)*u\n",
    "            x_point[j] = a_lim + (b_lim - a_lim) * u\n",
    "            \n",
    "        g_values[i] = g(x_point)\n",
    "\n",
    "    # --- Statistics ---\n",
    "    # Mean of g\n",
    "    mean_g = mean(g_values)\n",
    "    \n",
    "    # Integral Estimate = Volume * Mean\n",
    "    I_hat = vol * mean_g\n",
    "    \n",
    "    # Variance of g (sample variance)\n",
    "    var_g = var(g_values)\n",
    "    \n",
    "    # Standard Error = Volume * sqrt(Var(g) / N)\n",
    "    SE = vol * np.sqrt(var_g / N)\n",
    "    \n",
    "    # 95% CI (Z = 1.96)\n",
    "    z_score = 1.96\n",
    "    ci_lower = I_hat - z_score * SE\n",
    "    ci_upper = I_hat + z_score * SE\n",
    "    \n",
    "    # Relative Error\n",
    "    rel_error = np.abs(I_hat - true_val) / true_val\n",
    "\n",
    "    # --- Task 2: Efficiency Ratio R ---\n",
    "    # E[g^2] approx mean(g^2)\n",
    "    E_g2 = np.mean(g_values**2)\n",
    "    # E[g]^2 approx mean(g)^2\n",
    "    E_g_sq = mean_g**2\n",
    "    \n",
    "    # R = E[g^2] / E[g]^2\n",
    "    # Note: If mean_g is very close to 0, this might be unstable, \n",
    "    # but for this integral it should be fine.\n",
    "    R = E_g2 / E_g_sq\n",
    "\n",
    "    # Output Row\n",
    "    print(f\"{int(N):<9} {I_hat:<10.4f} {SE:<10.4f} [{ci_lower:.3f}, {ci_upper:.3f}]   {rel_error:<10.4f} {R:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n dimensional Sphere Volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# True value of volume according to formula specified above\n",
    "def analytic_sphere_volume(n):\n",
    "    \"\"\"Calculates the true volume of a unit n-sphere.\"\"\"\n",
    "    return (math.pi**(n/2)) / math.gamma(n/2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    r_2 = sum(x**2)\n",
    "    return 1 if r_2 <= 1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Setup ---\n",
    "a_lim, b_lim = 0, 1\n",
    "d = 2 \n",
    "\n",
    "# Volume of the integration domain (Hypercube [0,1]^6)\n",
    "vol_hypercube = (b_lim - a_lim)**d \n",
    "\n",
    "# Calculate the TRUE volume for comparison\n",
    "true_val_full = analytic_sphere_volume(d)\n",
    "\n",
    "# NOTE: The integral over [0,1] is only 1/(2^n) of the full sphere.\n",
    "true_val_region = true_val_full / (2**d)\n",
    "\n",
    "seed = 123456\n",
    "rng = np.random.default_rng(seed) \n",
    "\n",
    "N_vals = [1e4, 1e5, 1e6]\n",
    "\n",
    "print(f\"Dimension: {d}\")\n",
    "print(f\"True Volume (Full Sphere): {true_val_full:.5f}\")\n",
    "print(f\"True Integral (Region [0,1]^{d}): {true_val_region:.5f}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'N':<9} {'Estimate':<10} {'SE':<10} {'95% CI':<25} {'Rel Error %':<12}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for n_val in N_vals:\n",
    "    N = int(n_val)\n",
    "    \n",
    "    # Pre-allocate array for g(x) results\n",
    "    g_values = np.zeros(N)\n",
    "    \n",
    "    # --- Generation & Evaluation Loop ---\n",
    "    for i in range(N):\n",
    "        x_point = rng.uniform(a_lim, b_lim, d)\n",
    "        g_values[i] = g(x_point)\n",
    "\n",
    "    # --- Statistics ---\n",
    "    mean_g = np.mean(g_values)\n",
    "    \n",
    "    # Integral Estimate\n",
    "    I_hat = vol_hypercube * mean_g * (2**d) # 2^d to get total volume \n",
    "    \n",
    "    # Standard Error\n",
    "    variance = mean_g * (1 - mean_g) \n",
    "    se_g = np.sqrt(variance / N)\n",
    "    \n",
    "    # Scale SE by volume of hypercube\n",
    "    se_volume = vol_hypercube * se_g\n",
    "    \n",
    "    # 95% Confidence Interval\n",
    "    ci_lower = I_hat - (1.96 * se_volume)\n",
    "    ci_upper = I_hat + (1.96 * se_volume)\n",
    "    \n",
    "    # Relative Error\n",
    "    rel_error = abs(I_hat - true_val_region) / true_val_region\n",
    "\n",
    "    print(f\"{N:<9.0f} {I_hat:<10.5f} {se_volume:<10.5f} [{ci_lower:.5f}, {ci_upper:.5f}]   {rel_error*100:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Manual Helper Functions (No scipy allowed) ---\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"The function to integrate: e^(-2|x-5|)\"\"\"\n",
    "    # np.exp and np.abs are basic element-wise math (allowed)\n",
    "    return np.exp(-2 * np.abs(x - 5))\n",
    "\n",
    "# --- 2. Probability Functions ---\n",
    "def q_pdf_gaussian(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    The Proposal Distribution: N(5, 1)\n",
    "    \"\"\"\n",
    "    coeff = 1.0 / (sigma * math.sqrt(2 * math.pi))\n",
    "    exponent = -0.5 * ((x - mu) / sigma)**2\n",
    "    return coeff * np.exp(exponent)\n",
    "\n",
    "def p_val_uniform(x):\n",
    "    \"\"\"\n",
    "    The Target P(x). \n",
    "    NOTE: To match the slide's return statement (which has no *10 multiplier),\n",
    "    p(x) here acts as the 'Indicator Function' (1.0) inside the bounds,\n",
    "    rather than the PDF density (0.1). This allows the 'mean' to equal the 'Integral'.\n",
    "    \"\"\"\n",
    "    if 0 <= x <= 10:\n",
    "        return 1.0 \n",
    "    return 0.0\n",
    "\n",
    "# --- 3. The Slide Implementation ---\n",
    "def run_simulation(N=10000):\n",
    "    \n",
    "    # ===============================================\n",
    "    # STRATEGY 1: Crude Monte Carlo (Uniform)\n",
    "    # Logic: Integral = Volume * Mean(f)\n",
    "    # ===============================================\n",
    "    \n",
    "    # 1. Sample Uniformly [0, 10]\n",
    "    x_crude = np.random.uniform(0, 10, N)\n",
    "    \n",
    "    # 2. Calculate f_i\n",
    "    # Using list comprehension since we aren't using vector operations for logic\n",
    "    f_vals_crude = [np.exp(-2 * np.abs(val - 5)) for val in x_crude]\n",
    "    \n",
    "    # 3. Slide Logic Return\n",
    "    # I = 10 * mean(f_i)\n",
    "    I_crude = 10 * mean(f_vals_crude)\n",
    "    \n",
    "    # Var = (10^2 / N) * var(f_i)\n",
    "    Var_crude = (10**2 / N) * var(f_vals_crude)\n",
    "\n",
    "\n",
    "    # ===============================================\n",
    "    # STRATEGY 2: Importance Sampling (Gaussian)\n",
    "    # Logic: Integral = Mean(f * w)\n",
    "    # ===============================================\n",
    "    \n",
    "    weighted_terms = []\n",
    "    \n",
    "    # 1. Sample Normal(5, 1)\n",
    "    x_is = np.random.normal(5, 1, N)\n",
    "    \n",
    "    for val in x_is:\n",
    "        # Check bounds (Slide logic: if 0 <= x_i <= 10)\n",
    "        if 0 <= val <= 10:\n",
    "            \n",
    "            # Calculate q(x) - The Gaussian probability\n",
    "            q_i = q_pdf_gaussian(val, 5, 1)\n",
    "            \n",
    "            # Calculate p(x)\n",
    "            p_i = p_val_uniform(val) \n",
    "            \n",
    "            # w_i = p(x_i) / q(x_i)\n",
    "            w_i = p_i / q_i\n",
    "            \n",
    "            # f_i = exp(-2 * |x - 5|)\n",
    "            f_i = f(val)\n",
    "            \n",
    "            # store f_i * w_i\n",
    "            weighted_terms.append(f_i * w_i)\n",
    "            \n",
    "        else:\n",
    "            # If outside bounds, the contribution to the integral is 0\n",
    "            weighted_terms.append(0.0)\n",
    "            \n",
    "    # 3. Slide Logic Return\n",
    "    # Note: No '10' multiplier here, exactly as shown in the slide.\n",
    "    I_is = mean(weighted_terms)\n",
    "    \n",
    "    # Var = var(f_i * w_i) / N\n",
    "    # Note: No '100' multiplier here, exactly as shown in the slide.\n",
    "    Var_is = var(weighted_terms) / N\n",
    "\n",
    "    return I_crude, Var_crude, I_is, Var_is\n",
    "\n",
    "\n",
    "\n",
    "# --- Run and Print Results ---\n",
    "if __name__ == \"__main__\":\n",
    "    N_samples = [1e2, 1e3,1e4,1e5]\n",
    "    Ic_vals = []\n",
    "    Ii_vals = []\n",
    "    Vc_vals = []\n",
    "    Vi_vals = []\n",
    "    for i in N_samples:\n",
    "        I_c, V_c, I_i, V_i = run_simulation(int(i))\n",
    "        Ic_vals.append(I_c)\n",
    "        Ii_vals.append(I_i)\n",
    "        Vc_vals.append(V_c)\n",
    "        Vi_vals.append(V_i)\n",
    "\n",
    "    print(f\"--- Results for N={N_samples} ---\")\n",
    "    print(f\"True Integral Value: ~1.000 (approx)\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Crude Monte Carlo:\")\n",
    "    print(f\"  Estimate: {I_c:.5f}\")\n",
    "    print(f\"  Variance: {V_c:.6f}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Importance Sampling:\")\n",
    "    print(f\"  Estimate: {I_i:.5f}\")\n",
    "    print(f\"  Variance: {V_i:.6f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Avoid division by zero if variance is extremely small\n",
    "    if V_i > 0:\n",
    "        ratio = V_c / V_i\n",
    "        print(f\"Variance Reduction Factor: {ratio:.1f}x\")\n",
    "    else:\n",
    "        print(\"Variance Reduction: Infinite (perfect match)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error bars\n",
    "# fmt='-o' connects points with a line and uses circle markers\n",
    "# capsize=5 adds the horizontal lines at the top/bottom of the error bars\n",
    "plt.plot(N_samples, Ic_vals, label=r'I crude')\n",
    "plt.plot(N_samples, Ii_vals, label = r'I MC')\n",
    "# Plot the True Pi reference line\n",
    "plt.axhline(y=1, color='r', linestyle='--', label=r'True value')\n",
    "\n",
    "# 5. Formatting to match the screenshot\n",
    "plt.xscale('log') # Logarithmic X-axis for 10^3, 10^4...\n",
    "plt.xlabel(r'Number of samples $N$')\n",
    "plt.ylabel(r'Estimate $\\hat{I}$')\n",
    "plt.title('Convergence of Monte Carlo Estimate')\n",
    "plt.grid(True, which=\"both\", linestyle=':', alpha=0.7) # Dotted grid lines\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error bars\n",
    "# fmt='-o' connects points with a line and uses circle markers\n",
    "# capsize=5 adds the horizontal lines at the top/bottom of the error bars\n",
    "plt.plot(N_samples, Vc_vals, label=r'I=V crude')\n",
    "plt.plot(N_samples, Vi_vals, label = r'V MC')\n",
    "\n",
    "# 5. Formatting to match the screenshot\n",
    "plt.xscale('log') # Logarithmic X-axis for 10^3, 10^4...\n",
    "plt.xlabel(r'Number of samples $N$')\n",
    "plt.ylabel(r'Var$')\n",
    "plt.title('Variance vs Sample size')\n",
    "plt.grid(True, which=\"both\", linestyle=':', alpha=0.7) # Dotted grid lines\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
